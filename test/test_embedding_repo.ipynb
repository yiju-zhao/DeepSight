{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of models failed: Traceback (most recent call last):\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 335, in update_class\n",
      "    if (old_obj == new_obj) is True:\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/sqlalchemy/sql/operators.py\", line 582, in __eq__\n",
      "    return self.operate(eq, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py\", line 453, in operate\n",
      "    return op(self.comparator, *other, **kwargs)  # type: ignore[no-any-return]  # noqa: E501\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jiwenyu/Dev/jwgen/jwenv/lib/python3.11/site-packages/sqlalchemy/orm/relationships.py\", line 756, in __eq__\n",
      "    raise sa_exc.InvalidRequestError(\n",
      "sqlalchemy.exc.InvalidRequestError: Can't compare a collection to an object or collection; use contains() to test for membership.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 将上一级目录添加到模块搜索路径\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection\n",
    "from pymilvus import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection paper_collection already exists.\n"
     ]
    }
   ],
   "source": [
    "connections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "collection_name = \"paper_collection\"\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"paper_id\", dtype=DataType.INT64),  # 论文 ID\n",
    "    FieldSchema(name=\"chunk_id\", dtype=DataType.INT64),  # 论文中的 chunk 序号\n",
    "    FieldSchema(name=\"chunk_text\", dtype=DataType.VARCHAR, max_length=5000),  # chunk 原始文本\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768),  # chunk 向量\n",
    "    FieldSchema(name=\"chunk_type\", dtype=DataType.VARCHAR, max_length=50),  # chunk 类型 (如 abstract, conclusion)\n",
    "]\n",
    "schema = CollectionSchema(fields, description=\"Collection for paper embeddings\")\n",
    "\n",
    "vdb_collection = None\n",
    "if not utility.has_collection(collection_name):\n",
    "    vdb_collection = Collection(name=collection_name, schema=schema)\n",
    "    print(f\"Collection {collection_name} created.\")\n",
    "else:\n",
    "    vdb_collection = Collection(name=collection_name)\n",
    "    print(f\"Collection {collection_name} already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repositories import EmbeddingRepository\n",
    "embedding_repository = EmbeddingRepository(vdb_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in collection 'paper_collection': 46\n"
     ]
    }
   ],
   "source": [
    "# 获取集合中的总实体数\n",
    "total_entities = vdb_collection.num_entities\n",
    "print(f\"Total records in collection '{collection_name}': {total_entities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 collection 中的所有实体数据\n",
    "vdb_collection.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper_title', 'author_ids', 'author_names', 'venue', 'research_area', 'keywords', 'tldr', 'abstract', 'url', 'pdf_url', 'attachment_url', 'pdf_path']\n",
      "Stress-Testing Capability Elicitation With Password-Locked Models\n",
      "To determine the safety of large language models (LLMs), AI developers must be able to assess their dangerous capabilities. But simple prompting strategies often fail to elicit an LLM’s full capabilities. One way to elicit capabilities more robustly is to fine-tune the LLM to complete the task. In this paper, we investigate the conditions under which fine-tuning-based elicitation suffices to elicit capabilities. To do this, we introduce password-locked models, LLMs fine-tuned such that some of their capabilities are deliberately hidden. Specifically, these LLMs are trained to exhibit these capabilities only when a password is present in the prompt, and to imitate a much weaker LLM otherwise. Password-locked models enable a novel method of evaluating capabilities elicitation methods, by testing whether these password-locked capabilities can be elicited without using the password. We find that a few high-quality demonstrations are often sufficient to fully elicit password-locked capabilities. More surprisingly, fine-tuning can elicit other capabilities that have been locked using the same password, or even different passwords. Furthermore, when only evaluations, and not demonstrations, are available, approaches like reinforcement learning are still often able to elicit capabilities. Overall, our findings suggest that fine-tuning is an effective method of eliciting hidden capabilities of current models but may be unreliable when high-quality demonstrations are not available, e.g., as may be the case when models’ (hidden) capabilities exceed those of human demonstrators.\n",
      "[\"['Ryan Greenblatt'\", \" 'Fabien Roger'\", \" 'Dmitrii Krasheninnikov'\", \" 'David Krueger']\"]\n",
      "[\"['~Ryan_Greenblatt1'\", \" '~Fabien_Roger1'\", \" '~Dmitrii_Krasheninnikov1'\", \" '~David_Krueger1']\"]\n",
      "pdfs/zzOOqD6R1b.pdf\n",
      "We train models to behave poorly except when the prompt contains a password, and study when supervised fine-tuning and RL can recover high performance.\n",
      "NeurIPS 2024 poster\n",
      "safety_in_machine_learning\n",
      "[\"['LLMs'\", \" 'Elicitation'\", \" 'Fine-tuning'\", \" 'Sandbagging'\", \" 'Red-teaming'\", \" 'Safety']\"]\n",
      "https://openreview.net/forum?id=zzOOqD6R1b\n",
      "--------------------------------------------------------------------------------\n",
      "Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging\n",
      "Existing reconstruction models in snapshot compressive imaging systems (SCI) are trained with a single well-calibrated hardware instance, making their perfor- mance vulnerable to hardware shifts and limited in adapting to multiple hardware configurations. To facilitate cross-hardware learning, previous efforts attempt to directly collect multi-hardware data and perform centralized training, which is impractical due to severe user data privacy concerns and hardware heterogeneity across different platforms/institutions. In this study, we explicitly consider data privacy and heterogeneity in cooperatively optimizing SCI systems by proposing a Federated Hardware-Prompt learning (FedHP) framework. Rather than mitigating the client drift by rectifying the gradients, which only takes effect on the learning manifold but fails to solve the heterogeneity rooted in the input data space, FedHP learns a hardware-conditioned prompter to align inconsistent data distribution across clients, serving as an indicator of the data inconsistency among different hardware (e.g., coded apertures). Extensive experimental results demonstrate that the proposed FedHP coordinates the pre-trained model to multiple hardware con- figurations, outperforming prevalent FL frameworks for 0.35dB under challenging heterogeneous settings. Moreover, a Snapshot Spectral Heterogeneous Dataset has been built upon multiple practical SCI systems. Data and code are aveilable at https://github.com/Jiamian-Wang/FedHP-Snapshot-Compressive-Imaging.git\n",
      "[\"['Jiamian Wang'\", \" 'Zongliang Wu'\", \" 'Yulun Zhang'\", \" 'Xin Yuan'\", \" 'Tao Lin'\", \" 'ZHIQIANG TAO']\"]\n",
      "[\"['~Jiamian_Wang1'\", \" '~Zongliang_Wu1'\", \" '~Yulun_Zhang1'\", \" '~Xin_Yuan4'\", \" '~Tao_Lin1'\", \" '~ZHIQIANG_TAO2']\"]\n",
      "pdfs/zxSWIdyW3A.pdf\n",
      "nan\n",
      "NeurIPS 2024 poster\n",
      "machine_vision\n",
      "[\"['snapshot compressive imaging'\", \" 'hyperpectral imaging'\", \" 'prompt learning'\", \" 'federated learning']\"]\n",
      "https://openreview.net/forum?id=zxSWIdyW3A\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 处理元数据\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "csv_file = \"../data/papers_metadata.csv\" \n",
    "metadata_df = pd.read_csv(csv_file)\n",
    "\n",
    "# 打印数据表格\n",
    "print(metadata_df.columns.to_list())\n",
    "# CSV标题：paper_title,author_ids,author_names,venue,research_area,keywords,tldr,abstract,url,pdf_url,attachment_url,pdf_path\n",
    "\n",
    "# use a for loop to print first 2 row all data columns\n",
    "for index, row in metadata_df[:2].iterrows():\n",
    "     print(row[\"paper_title\"])\n",
    "     print(row[\"abstract\"])\n",
    "     print(row[\"author_names\"].split(\",\"))\n",
    "     print(row[\"author_ids\"].split(\",\"))\n",
    "     print(row[\"pdf_path\"])\n",
    "     print(row[\"tldr\"])\n",
    "     print(row[\"venue\"])\n",
    "     print(row[\"research_area\"])\n",
    "     print(row[\"keywords\"].split(\",\"))\n",
    "     print(row[\"url\"])\n",
    "     print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.ollama_model import OllamaModel\n",
    "from paper_agent import PDFAnalyzer\n",
    "\n",
    "# create ollama model\n",
    "llm = OllamaModel()\n",
    "\n",
    "for index, row in metadata_df[:1].iterrows():\n",
    "    pdf_path = \"../data/pdfs/neurips/2024/Stress_Testing_Capability_Elicitation_With_Password_Locked_Models.pdf\"\n",
    "    \n",
    "    # Create a PDFAnalyzer object\n",
    "    # CSV标题：paper_title,author_ids,author_names,venue,research_area,keywords,tldr,abstract,url,pdf_url,attachment_url,pdf_path\n",
    "\n",
    "    pdf_analyzer = PDFAnalyzer(\n",
    "        title= row[\"paper_title\"],\n",
    "        abstract= row[\"abstract\"],\n",
    "        author_names= row[\"author_names\"].split(\",\"),\n",
    "        author_ids= row[\"author_ids\"].split(\",\"),\n",
    "        pdf_path=pdf_path,\n",
    "        tldr=row[\"tldr\"],\n",
    "        keywords=row[\"keywords\"].split(\",\"),\n",
    "        llm=llm\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:paper_agent:Converted PDF to text: Stress-Testing Capability Elicitation With\n",
      "Password-Locked Models\n",
      "\n",
      "Ryan Greenblatt∗\n",
      "Redwood Research\n",
      "\n",
      "INFO:paper_agent:Detected title: limitations at line 1120\n",
      "INFO:paper_agent:Split text into 42 chunks\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:paper_agent:the main paper content has been slit into 42 chunks\n"
     ]
    }
   ],
   "source": [
    "text = pdf_analyzer.extract_text(pdf_path=pdf_analyzer.pdf_path)\n",
    "text_lines =pdf_analyzer.extract_text_lines(text)\n",
    "title_indices = pdf_analyzer.get_section_title_indices(text_lines)\n",
    "section_lines_dict = pdf_analyzer.split_text_lines_by_section_title(text_lines, title_indices)\n",
    "\n",
    "embedding_list = pdf_analyzer.embed_main_text(llm, section_lines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "['abstract', 'introduction', 'introduction', 'introduction', 'introduction', 'introduction', 'introduction', 'related_work', 'related_work', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'experiment', 'methodology', 'methodology', 'methodology', 'methodology', 'limitations', 'limitations', 'conclusion', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0', 'limitations_0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repositories.embedding_repository:Successfully inserted 42 chunks for paper 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_repository.insert_chunks_batch(2,embedding_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

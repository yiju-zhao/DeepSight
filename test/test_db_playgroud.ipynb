{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import models\n",
    "from models import Base, Conference, ConferenceInstance, Paper, Author, PaperAuthors, Affiliation, AuthorAffiliation, Keyword, PaperKeyword, Reference, PaperReference, ContentEmbedding  # 导入您的模型\n",
    "\n",
    "# 强制重新加载模块\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import date\n",
    "from models import *\n",
    "\n",
    "# 配置本地 PostgreSQL 数据库 URL\n",
    "DATABASE_URL = \"postgresql://postgres:nasa718@localhost/test_db\"\n",
    "engine = create_engine(DATABASE_URL, echo=True)\n",
    "\n",
    "# 创建会话\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "session = SessionLocal()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插入一个conference instance\n",
    "# 查询所有会议实例\n",
    "conference_instances = session.query(ConferenceInstance).all()\n",
    "for instance in conference_instances:\n",
    "    print(instance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有状态的对象\n",
    "print(\"New objects:\")\n",
    "for obj in session.new:\n",
    "    print(obj)\n",
    "\n",
    "print(\"Dirty objects:\")\n",
    "for obj in session.dirty:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建所有表\n",
    "Base.metadata.create_all(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询所有表的数据\n",
    "affiliations = session.query(Affiliation).all()\n",
    "authors = session.query(Author).all()\n",
    "conferences = session.query(Conference).all()\n",
    "conference_instances = session.query(ConferenceInstance).all()\n",
    "content_embeddings = session.query(ContentEmbedding).all()\n",
    "keywords = session.query(Keyword).all()\n",
    "papers = session.query(Paper).all()\n",
    "references = session.query(Reference).all()\n",
    "\n",
    "# 打印查询结果\n",
    "print(\"\\n=== Affiliations ===\")\n",
    "for affiliation in affiliations:\n",
    "    print(affiliation)\n",
    "\n",
    "print(\"\\n=== Authors ===\")\n",
    "for author in authors:\n",
    "    print(author)\n",
    "\n",
    "print(\"\\n=== Conferences ===\")\n",
    "for conference in conferences:\n",
    "    print(conference)\n",
    "\n",
    "print(\"\\n=== Conference Instances ===\")\n",
    "for instance in conference_instances:\n",
    "    print(instance)\n",
    "\n",
    "print(\"\\n=== Content Embeddings ===\")\n",
    "for embedding in content_embeddings:\n",
    "    print(embedding)\n",
    "\n",
    "print(\"\\n=== Keywords ===\")\n",
    "for keyword in keywords:\n",
    "    print(keyword)\n",
    "\n",
    "print(\"\\n=== Papers ===\")\n",
    "for paper in papers:\n",
    "    print(paper)\n",
    "\n",
    "print(\"\\n=== References ===\")\n",
    "for reference in references:\n",
    "    print(reference)\n",
    "\n",
    "# 关闭会话\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除所有表的数据\n",
    "session = SessionLocal()\n",
    "\n",
    "session.query(Affiliation).delete()\n",
    "session.query(Author).delete()\n",
    "session.query(ContentEmbedding).delete()\n",
    "session.query(Keyword).delete()\n",
    "session.query(Reference).delete()\n",
    "session.query(Paper).delete()\n",
    "session.query(ConferenceInstance).delete()\n",
    "session.query(Conference).delete()\n",
    "\n",
    "# 提交事务\n",
    "session.commit()\n",
    "\n",
    "print(\"All data has been deleted.\")\n",
    "\n",
    "# 关闭会话\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插入数据测试\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    embedding_array = np.random.rand(768)  # 生成 768 维随机浮点数向量（范围 [0,1]）\n",
    "    # 将 np.float64 转换为普通的 Python float\n",
    "    embedding = [float(value) for value in embedding_array]  # embedding_array 是一个 numpy 数组\n",
    "    return embedding\n",
    "\n",
    "try:\n",
    "    # 插入 Affiliation（单位）\n",
    "    affiliation1 = Affiliation(name=\"MIT\", type=\"University\")\n",
    "    affiliation2 = Affiliation(name=\"Stanford University\", type=\"University\")\n",
    "\n",
    "    session.add_all([affiliation1, affiliation2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 Author（作者）\n",
    "    # 获取一个已存在的 Affiliation（例如，MIT）\n",
    "    affiliation = session.query(Affiliation).filter_by(name=\"MIT\").first()\n",
    "    # 创建新的 Author 对象，并将 Affiliation 关联到该作者\n",
    "    author1 = Author(author_id = \"~jodn_doe\", name=\"John Doe\", affiliations=[affiliation])\n",
    "\n",
    "    affiliation2 = session.query(Affiliation).filter_by(name=\"Stanford University\").first()\n",
    "    author2 = Author(author_id = \"~jodn_doe\", name=\"John Doe\", affiliations=[affiliation2])\n",
    "\n",
    "    session.add_all([author1, author2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 Conference（会议）\n",
    "    conference1 = Conference(name=\"NeurIPS\", type=\"ML Conference\", description=\"Neural Information Processing Systems\")\n",
    "    conference2 = Conference(name=\"ICML\", type=\"ML Conference\", description=\"International Conference on Machine Learning\")\n",
    "\n",
    "    session.add_all([conference1, conference2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 ConferenceInstance（会议届次）\n",
    "    instance1 = ConferenceInstance(name=\"NeurIPS 2025\", conference_id=conference1.conference_id, year=2025, start_date=\"2025-12-01\", end_date=\"2025-12-07\", location=\"New Orleans\", website=\"https://neurips.cc/2025\")\n",
    "    instance2 = ConferenceInstance(name=\"ICML 2025\", conference_id=conference2.conference_id, year=2025, start_date=\"2025-07-01\", end_date=\"2025-07-05\", location=\"Paris\", website=\"https://icml.cc/2025\")\n",
    "\n",
    "    session.add_all([instance1, instance2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 Paper（论文）\n",
    "    paper1 = Paper(title=\"Deep Learning Advances\", year=2025, instance=instance1)\n",
    "    paper2 = Paper(title=\"Graph Neural Networks\", year=2025, instance=instance2)\n",
    "\n",
    "    session.add_all([paper1, paper2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 Keyword（关键词）\n",
    "    keyword1 = Keyword(keyword=\"Deep Learning\")\n",
    "    keyword2 = Keyword(keyword=\"GNN\")\n",
    "\n",
    "    session.add_all([keyword1, keyword2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 Paper - Keyword 关系（多对多）\n",
    "    paper1.keywords.append(keyword1)\n",
    "    paper2.keywords.append(keyword2)\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 ContentEmbedding（嵌入向量）\n",
    "    embedding1 = ContentEmbedding(paper_id=paper1.paper_id, embedding=get_text_embedding(\"text\"))\n",
    "    embedding2 = ContentEmbedding(paper_id=paper2.paper_id, embedding=get_text_embedding(\"text\"))\n",
    "\n",
    "    session.add_all([embedding1, embedding2])\n",
    "    session.commit()\n",
    "\n",
    "    # 插入 Reference（参考文献）\n",
    "    reference1 = Reference(\n",
    "        title=\"Sample Paper Title\",\n",
    "        author=\"John Doe, Jane Smith\",\n",
    "        year=2025,\n",
    "        journal=\"Sample Journal\",\n",
    "        web_url=\"https://example.com\"\n",
    "    )\n",
    "    reference1.papers.append(paper1)\n",
    "    reference1.papers.append(paper2)\n",
    "\n",
    "    session.add(reference1)\n",
    "    session.commit()\n",
    "\n",
    "    print(\"✅ Dummy 数据插入成功！\")\n",
    "\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    print(f\"❌ 发生错误: {e}\")\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('neurips_2024_papers_index.csv')\n",
    "\n",
    "test_row = df.iloc[1618]\n",
    "\n",
    "test_author_list = test_row['Author Names'].split(', ')\n",
    "print(test_row['Paper Title'])\n",
    "print(test_author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_analyzer import PDFAnalyzer\n",
    "\n",
    "pdf_path = '/Users/eason/Documents/Project/Agent/mytinyagent/test_paper/1619.pdf'\n",
    "analyzer = PDFAnalyzer(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = analyzer.get_references_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_author = analyzer.extract_author_info(test_author_list)\n",
    "print(extracted_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_references = analyzer.extract_references_info()\n",
    "print(extracted_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility\n",
    "\n",
    "# URL returning HTML\n",
    "url = f\"https://openreview.net/forum?id=zzOOqD6R1b&referrer=%5Bthe%20profile%20of%20David%20Krueger%5D(%2Fprofile%3Fid%3D~David_Krueger1)\"\n",
    "\n",
    "# URL returning PDF\n",
    "date = utility.get_date_from_openreview(url)\n",
    "date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
